{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021d2bb2-e274-452b-824d-cc27040b743b",
   "metadata": {
    "is_executing": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "116f3cd0-59c8-49f4-98ba-96489dd9c47e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-30T01:48:35.835481Z",
     "iopub.status.busy": "2025-09-30T01:48:35.834471Z",
     "iopub.status.idle": "2025-09-30T01:48:50.226883Z",
     "shell.execute_reply": "2025-09-30T01:48:50.225848Z",
     "shell.execute_reply.started": "2025-09-30T01:48:35.835434Z"
    },
    "is_executing": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import kaggle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms as T\n",
    "import time\n",
    "import copy\n",
    "import csv\n",
    "import os, shutil\n",
    "\n",
    "from timm.data import Mixup\n",
    "from timm.loss import SoftTargetCrossEntropy\n",
    "import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d8300f-fb86-453b-85dd-1f0f1bf081f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-27T02:02:56.290297Z",
     "iopub.status.busy": "2025-09-27T02:02:56.288963Z"
    },
    "is_executing": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "kaggle.api.authenticate()\n",
    "kaggle.api.dataset_download_files('Dorikan/Airport-Tools-Crops', path='/home/jupyter/datasphere/filestore/datasets/', unzip=True)\n",
    "\n",
    "!unzip -d /home/jupyter/datasphere/project /home/jupyter/datasphere/filestore/datasets/Airport-Tools-Crops.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c61e344-2461-444d-89c6-c01984892c9c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-27T02:15:55.763403Z",
     "iopub.status.busy": "2025-09-27T02:15:55.762493Z",
     "iopub.status.idle": "2025-09-27T02:27:09.595687Z",
     "shell.execute_reply": "2025-09-27T02:27:09.594194Z",
     "shell.execute_reply.started": "2025-09-27T02:15:55.763348Z"
    },
    "is_executing": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!rm -f /home/jupyter/datasphere/filestore/datasets/Airport-Tools-Crops.zip\n",
    "!rm -rf /home/jupyter/datasphere/filestore/datasets/dataset_crops\n",
    "!mv /home/jupyter/datasphere/project/dataset_crops /home/jupyter/datasphere/filestore/datasets/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7996498-7a57-448f-b774-3e372ef52671",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-30T01:48:50.229990Z",
     "iopub.status.busy": "2025-09-30T01:48:50.228910Z",
     "iopub.status.idle": "2025-09-30T01:48:50.254406Z",
     "shell.execute_reply": "2025-09-30T01:48:50.253140Z",
     "shell.execute_reply.started": "2025-09-30T01:48:50.229943Z"
    },
    "is_executing": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class EfficientNetWithEmbeddings(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.base = models.efficientnet_b0(pretrained=True)\n",
    "        self.feature_extractor = self.base.features\n",
    "        self.pool = self.base.avgpool\n",
    "        self.embedding_layer = nn.Flatten()\n",
    "        in_features = self.base.classifier[1].in_features\n",
    "        self.fc = nn.Linear(in_features, num_classes)\n",
    "\n",
    "    def forward(self, x, return_embedding=False):\n",
    "        x = self.feature_extractor(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.embedding_layer(x)\n",
    "        if return_embedding:\n",
    "            return x\n",
    "        out = self.fc(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef38baadcbb01dd4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-30T02:00:21.893292Z",
     "iopub.status.busy": "2025-09-30T02:00:21.891747Z",
     "iopub.status.idle": "2025-09-30T02:00:21.918322Z",
     "shell.execute_reply": "2025-09-30T02:00:21.916865Z",
     "shell.execute_reply.started": "2025-09-30T02:00:21.893229Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_epochs = 60\n",
    "batch_size = 128\n",
    "learning_rate = 1e-3\n",
    "save_path = '/home/jupyter/datasphere/filestore/training/efficientnet-b0-screwdriver_training'\n",
    "os.makedirs(save_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13ceabb064e7cc7d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-30T01:48:50.332779Z",
     "iopub.status.busy": "2025-09-30T01:48:50.331534Z",
     "iopub.status.idle": "2025-09-30T01:48:50.356748Z",
     "shell.execute_reply": "2025-09-30T01:48:50.355688Z",
     "shell.execute_reply.started": "2025-09-30T01:48:50.332729Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, num_epochs=25, scheduler=None):\n",
    "    since = time.time()\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    log_file = os.path.join(save_path, \"training_log.csv\")\n",
    "    with open(log_file, mode=\"w\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"epoch\", \"train_loss\", \"train_acc\", \"val_loss\", \"val_acc\"])\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "        print(\"-\" * 20)\n",
    "\n",
    "        epoch_stats = {}\n",
    "\n",
    "        for phase in [\"train\", \"valid\"]:\n",
    "            if phase == \"train\":\n",
    "                model.train()\n",
    "                dataloader = train_loader\n",
    "                transforms = train_transforms\n",
    "            else:\n",
    "                model.eval()\n",
    "                dataloader = valid_loader\n",
    "                transforms = valid_transforms\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            for i, (inputs, labels) in enumerate(dataloader):\n",
    "                inputs = inputs.to(device)\n",
    "                inputs = transforms(inputs)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == \"train\"):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    if phase == \"train\":\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        if scheduler is not None:\n",
    "                            scheduler.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "                if i % 10 == 0:\n",
    "                    done = i * batch_size\n",
    "                    total = len(dataloader.dataset)\n",
    "                    print(f\"[{phase}] {done}/{total} samples processed...\")\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloader.dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloader.dataset)\n",
    "\n",
    "            epoch_stats[f\"{phase}_loss\"] = epoch_loss\n",
    "            epoch_stats[f\"{phase}_acc\"] = epoch_acc.item()\n",
    "\n",
    "            print(f\"{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\")\n",
    "\n",
    "            if phase == \"valid\" and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                torch.save(best_model_wts, f\"{save_path}/best_model.pth\")\n",
    "                print(\">> Saved best model.\")\n",
    "\n",
    "        # Сохраняем лог в CSV\n",
    "        with open(log_file, mode=\"a\", newline=\"\") as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([epoch+1,\n",
    "                             epoch_stats[\"train_loss\"], epoch_stats[\"train_acc\"],\n",
    "                             epoch_stats[\"valid_loss\"], epoch_stats[\"valid_acc\"]])\n",
    "\n",
    "        # Сохраняем каждые 5 эпох\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            torch.save(model.state_dict(), f\"{save_path}/epoch_{epoch+1}.pth\")\n",
    "            print(f\">> Saved checkpoint at epoch {epoch+1}\")\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f\"\\nTraining complete in {time_elapsed//60:.0f}m {time_elapsed%60:.0f}s\")\n",
    "    print(f\"Best val Acc: {best_acc:.4f}\")\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b34e6542a6de51c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-30T02:10:03.901863Z",
     "iopub.status.busy": "2025-09-30T02:10:03.900804Z",
     "iopub.status.idle": "2025-09-30T02:10:03.920489Z",
     "shell.execute_reply": "2025-09-30T02:10:03.919342Z",
     "shell.execute_reply.started": "2025-09-30T02:10:03.901819Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_transforms = torch.nn.Sequential(\n",
    "    T.RandomRotation(40),\n",
    "    #T.RandomPerspective(distortion_scale=0.5, p=0.5),\n",
    "    T.RandomAffine(degrees=0, translate=(0.2, 0.2), scale=(0.7, 1.3), shear=20),\n",
    "    T.RandomHorizontalFlip(p=0.5),\n",
    "    T.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.2),\n",
    "    T.GaussianBlur(kernel_size=5, sigma=(0.1, 2.0)),\n",
    "    #T.RandomGrayscale(p=0.2),\n",
    "    T.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225]),\n",
    "    T.RandomErasing(p=0.3, scale=(0.02, 0.2), ratio=(0.3, 3.3))\n",
    ").to(device)\n",
    "\n",
    "valid_transforms = torch.nn.Sequential(\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    ").to(device)\n",
    "\n",
    "\n",
    "\n",
    "tfs = T.Compose([\n",
    "    T.RandomResizedCrop(224),   # кроп до 224×224\n",
    "    T.transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4490ad7-8908-4b45-99f1-d44a87350432",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-30T02:10:03.923716Z",
     "iopub.status.busy": "2025-09-30T02:10:03.922557Z",
     "iopub.status.idle": "2025-09-30T02:10:03.977906Z",
     "shell.execute_reply": "2025-09-30T02:10:03.976618Z",
     "shell.execute_reply.started": "2025-09-30T02:10:03.923666Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = datasets.ImageFolder(\"/home/jupyter/datasphere/filestore/datasets/tmp/train\", transform=tfs) #\n",
    "valid_dataset = datasets.ImageFolder(\"/home/jupyter/datasphere/filestore/datasets/tmp/valid\", transform=tfs) #\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=8, pin_memory=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, num_workers=8, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b10524d2-03e8-4b77-a19e-79bd388dcb4b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-30T01:48:50.381226Z",
     "iopub.status.busy": "2025-09-30T01:48:50.379902Z",
     "iopub.status.idle": "2025-09-30T01:48:51.404435Z",
     "shell.execute_reply": "2025-09-30T01:48:51.403185Z",
     "shell.execute_reply.started": "2025-09-30T01:48:50.381170Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-3dd342df.pth\" to /tmp/xdg_cache/torch/hub/checkpoints/efficientnet_b0_rwightman-3dd342df.pth\n",
      "100%|██████████| 20.5M/20.5M [00:00<00:00, 80.3MB/s]\n"
     ]
    }
   ],
   "source": [
    "model = EfficientNetWithEmbeddings(num_classes=3)\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab4afe6ad79b004",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-30T02:00:32.844046Z",
     "iopub.status.busy": "2025-09-30T02:00:32.843091Z",
     "iopub.status.idle": "2025-09-30T02:10:03.884098Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/60\n",
      "--------------------\n",
      "[train] 0/1684 samples processed...\n",
      "[train] 1280/1684 samples processed...\n",
      "train Loss: 0.3635 Acc: 0.8397\n",
      "[valid] 0/439 samples processed...\n",
      "valid Loss: 0.2831 Acc: 0.9021\n",
      ">> Saved best model.\n",
      "\n",
      "Epoch 2/60\n",
      "--------------------\n",
      "[train] 0/1684 samples processed...\n",
      "[train] 1280/1684 samples processed...\n",
      "train Loss: 0.3417 Acc: 0.8640\n",
      "[valid] 0/439 samples processed...\n",
      "valid Loss: 0.3039 Acc: 0.8633\n",
      "\n",
      "Epoch 3/60\n",
      "--------------------\n",
      "[train] 0/1684 samples processed...\n",
      "[train] 1280/1684 samples processed...\n",
      "train Loss: 0.3794 Acc: 0.8314\n",
      "[valid] 0/439 samples processed...\n",
      "valid Loss: 0.4730 Acc: 0.8109\n",
      "\n",
      "Epoch 4/60\n",
      "--------------------\n",
      "[train] 0/1684 samples processed...\n",
      "[train] 1280/1684 samples processed...\n",
      "train Loss: 0.4142 Acc: 0.8284\n",
      "[valid] 0/439 samples processed...\n",
      "valid Loss: 0.4104 Acc: 0.8269\n",
      "\n",
      "Epoch 5/60\n",
      "--------------------\n",
      "[train] 0/1684 samples processed...\n",
      "[train] 1280/1684 samples processed...\n",
      "train Loss: 0.3023 Acc: 0.8741\n",
      "[valid] 0/439 samples processed...\n",
      "valid Loss: 0.3850 Acc: 0.8428\n",
      ">> Saved checkpoint at epoch 5\n",
      "\n",
      "Epoch 6/60\n",
      "--------------------\n",
      "[train] 0/1684 samples processed...\n",
      "[train] 1280/1684 samples processed...\n",
      "train Loss: 0.2902 Acc: 0.8824\n",
      "[valid] 0/439 samples processed...\n",
      "valid Loss: 0.3279 Acc: 0.8656\n",
      "\n",
      "Epoch 7/60\n",
      "--------------------\n",
      "[train] 0/1684 samples processed...\n",
      "[train] 1280/1684 samples processed...\n",
      "train Loss: 0.3847 Acc: 0.8379\n",
      "[valid] 0/439 samples processed...\n",
      "valid Loss: 0.2843 Acc: 0.8975\n",
      "\n",
      "Epoch 8/60\n",
      "--------------------\n",
      "[train] 0/1684 samples processed...\n",
      "[train] 1280/1684 samples processed...\n",
      "train Loss: 0.3629 Acc: 0.8492\n",
      "[valid] 0/439 samples processed...\n",
      "valid Loss: 0.3050 Acc: 0.8861\n",
      "\n",
      "Epoch 9/60\n",
      "--------------------\n",
      "[train] 0/1684 samples processed...\n",
      "[train] 1280/1684 samples processed...\n",
      "train Loss: 0.2979 Acc: 0.8765\n",
      "[valid] 0/439 samples processed...\n",
      "valid Loss: 0.2970 Acc: 0.8884\n",
      "\n",
      "Epoch 10/60\n",
      "--------------------\n",
      "[train] 0/1684 samples processed...\n",
      "[train] 1280/1684 samples processed...\n",
      "train Loss: 0.3040 Acc: 0.8783\n",
      "[valid] 0/439 samples processed...\n",
      "valid Loss: 0.3520 Acc: 0.8497\n",
      "train Loss: 0.2865 Acc: 0.8872\n",
      "[valid] 0/439 samples processed...\n",
      "valid Loss: 0.2643 Acc: 0.8975\n",
      ">> Saved checkpoint at epoch 20\n",
      "\n",
      "Epoch 21/60\n",
      "--------------------\n",
      "[train] 0/1684 samples processed...\n",
      "[train] 1280/1684 samples processed...\n",
      "train Loss: 0.3714 Acc: 0.8587\n",
      "[valid] 0/439 samples processed...\n",
      "valid Loss: 0.2916 Acc: 0.8861\n",
      "\n",
      "Epoch 22/60\n",
      "--------------------\n",
      "[train] 0/1684 samples processed...\n",
      "[train] 1280/1684 samples processed...\n",
      "train Loss: 0.3258 Acc: 0.8640\n",
      "[valid] 0/439 samples processed...\n",
      "valid Loss: 0.3026 Acc: 0.8838\n",
      "\n",
      "Epoch 23/60\n",
      "--------------------\n",
      "[train] 0/1684 samples processed...\n",
      "[train] 1280/1684 samples processed...\n",
      "train Loss: 0.2731 Acc: 0.8884\n",
      "[valid] 0/439 samples processed...\n",
      "valid Loss: 0.3292 Acc: 0.8747\n",
      "\n",
      "Epoch 24/60\n",
      "--------------------\n",
      "[train] 0/1684 samples processed...\n",
      "[train] 1280/1684 samples processed...\n",
      "train Loss: 0.3290 Acc: 0.8682\n",
      "[valid] 0/439 samples processed...\n",
      "valid Loss: 0.2925 Acc: 0.8815\n",
      "\n",
      "Epoch 25/60\n",
      "--------------------\n",
      "[train] 0/1684 samples processed...\n",
      "[train] 1280/1684 samples processed...\n",
      "train Loss: 0.2977 Acc: 0.8795\n",
      "[valid] 0/439 samples processed...\n",
      "valid Loss: 0.3459 Acc: 0.8610\n",
      ">> Saved checkpoint at epoch 25\n",
      "\n",
      "Epoch 26/60\n",
      "--------------------\n",
      "[train] 0/1684 samples processed...\n",
      "[train] 1280/1684 samples processed...\n",
      "train Loss: 0.3157 Acc: 0.8717\n",
      "[valid] 0/439 samples processed...\n",
      "valid Loss: 0.3221 Acc: 0.8679\n",
      "\n",
      "Epoch 27/60\n",
      "--------------------\n",
      "[train] 0/1684 samples processed...\n",
      "[train] 1280/1684 samples processed...\n",
      "train Loss: 0.2749 Acc: 0.8818\n",
      "[valid] 0/439 samples processed...\n",
      "valid Loss: 0.2234 Acc: 0.9271\n",
      ">> Saved best model.\n",
      "\n",
      "Epoch 28/60\n",
      "--------------------\n",
      "[train] 0/1684 samples processed...\n",
      "[train] 1280/1684 samples processed...\n",
      "train Loss: 0.3138 Acc: 0.8688\n",
      "[valid] 0/439 samples processed...\n",
      "valid Loss: 0.3006 Acc: 0.8907\n",
      "\n",
      "Epoch 29/60\n",
      "--------------------\n",
      "[train] 0/1684 samples processed...\n",
      "[train] 1280/1684 samples processed...\n",
      "train Loss: 0.2685 Acc: 0.8937\n",
      "[valid] 0/439 samples processed...\n",
      "valid Loss: 0.2420 Acc: 0.9157\n",
      "\n",
      "Epoch 30/60\n",
      "--------------------\n",
      "[train] 0/1684 samples processed...\n",
      "[train] 1280/1684 samples processed...\n",
      "train Loss: 0.2388 Acc: 0.8949\n",
      "[valid] 0/439 samples processed...\n",
      "valid Loss: 0.3468 Acc: 0.8838\n",
      ">> Saved checkpoint at epoch 30\n",
      "\n",
      "Epoch 31/60\n",
      "--------------------\n",
      "[train] 0/1684 samples processed...\n",
      "[train] 1280/1684 samples processed...\n",
      "train Loss: 0.2710 Acc: 0.8777\n",
      "[valid] 0/439 samples processed...\n",
      "valid Loss: 0.4783 Acc: 0.8041\n",
      "\n",
      "Epoch 32/60\n",
      "--------------------\n",
      "[train] 0/1684 samples processed...\n",
      "[train] 1280/1684 samples processed...\n",
      "train Loss: 0.2989 Acc: 0.8812\n",
      "[valid] 0/439 samples processed...\n",
      "valid Loss: 0.2841 Acc: 0.8952\n",
      "\n",
      "Epoch 33/60\n",
      "--------------------\n",
      "[train] 0/1684 samples processed...\n",
      "[train] 1280/1684 samples processed...\n",
      "train Loss: 0.4218 Acc: 0.8302\n",
      "[valid] 0/439 samples processed...\n",
      "valid Loss: 0.3599 Acc: 0.8610\n",
      "\n",
      "Epoch 34/60\n",
      "--------------------\n",
      "[train] 0/1684 samples processed...\n",
      "[train] 1280/1684 samples processed...\n",
      "train Loss: 0.2801 Acc: 0.8890\n",
      "[valid] 0/439 samples processed...\n",
      "valid Loss: 0.2841 Acc: 0.8815\n",
      "\n",
      "Epoch 35/60\n",
      "--------------------\n",
      "[train] 0/1684 samples processed...\n",
      "[train] 1280/1684 samples processed...\n",
      "train Loss: 0.2795 Acc: 0.8771\n",
      "[valid] 0/439 samples processed...\n",
      "valid Loss: 0.2706 Acc: 0.9089\n",
      ">> Saved checkpoint at epoch 35\n",
      "\n",
      "Epoch 36/60\n",
      "--------------------\n",
      "[train] 0/1684 samples processed...\n",
      "[train] 1280/1684 samples processed...\n",
      "train Loss: 0.3024 Acc: 0.8694\n",
      "[valid] 0/439 samples processed...\n",
      "valid Loss: 0.1926 Acc: 0.9317\n",
      ">> Saved best model.\n",
      "\n",
      "Epoch 37/60\n",
      "--------------------\n",
      "[train] 0/1684 samples processed...\n",
      "[train] 1280/1684 samples processed...\n",
      "train Loss: 0.2866 Acc: 0.8765\n",
      "[valid] 0/439 samples processed...\n",
      "valid Loss: 0.2059 Acc: 0.9317\n",
      "\n",
      "Epoch 38/60\n",
      "--------------------\n",
      "[train] 0/1684 samples processed...\n",
      "[train] 1280/1684 samples processed...\n",
      "train Loss: 0.2965 Acc: 0.8818\n",
      "[valid] 0/439 samples processed...\n",
      "valid Loss: 0.3040 Acc: 0.8793\n",
      "\n",
      "Epoch 39/60\n",
      "--------------------\n",
      "[train] 0/1684 samples processed...\n",
      "[train] 1280/1684 samples processed...\n",
      "train Loss: 0.3304 Acc: 0.8658\n",
      "[valid] 0/439 samples processed...\n",
      "valid Loss: 0.3509 Acc: 0.8588\n",
      "\n",
      "Epoch 40/60\n",
      "--------------------\n",
      "[train] 0/1684 samples processed...\n",
      "[train] 1280/1684 samples processed...\n",
      "train Loss: 0.3282 Acc: 0.8652\n",
      "[valid] 0/439 samples processed...\n",
      "valid Loss: 0.3105 Acc: 0.8929\n",
      ">> Saved checkpoint at epoch 40\n",
      "\n",
      "Epoch 41/60\n",
      "--------------------\n",
      "[train] 0/1684 samples processed...\n",
      "[train] 1280/1684 samples processed...\n",
      "train Loss: 0.2493 Acc: 0.8949\n",
      "[valid] 0/439 samples processed...\n",
      "valid Loss: 0.2214 Acc: 0.9226\n",
      "\n",
      "Epoch 42/60\n",
      "--------------------\n",
      "[train] 0/1684 samples processed...\n",
      "[train] 1280/1684 samples processed...\n",
      "train Loss: 0.3171 Acc: 0.8705\n",
      "[valid] 0/439 samples processed...\n",
      "valid Loss: 0.2955 Acc: 0.9112\n",
      "\n",
      "Epoch 43/60\n",
      "--------------------\n",
      "[train] 0/1684 samples processed...\n",
      "[train] 1280/1684 samples processed...\n",
      "train Loss: 0.2489 Acc: 0.8979\n",
      "[valid] 0/439 samples processed...\n",
      "valid Loss: 0.3459 Acc: 0.8724\n",
      "\n",
      "Epoch 44/60\n",
      "--------------------\n",
      "[train] 0/1684 samples processed...\n",
      "[train] 1280/1684 samples processed...\n",
      "train Loss: 0.2933 Acc: 0.8759\n",
      "[valid] 0/439 samples processed...\n",
      "valid Loss: 0.3899 Acc: 0.8451\n",
      "\n",
      "Epoch 45/60\n",
      "--------------------\n",
      "[train] 0/1684 samples processed...\n",
      "[train] 1280/1684 samples processed...\n",
      "train Loss: 0.2679 Acc: 0.8842\n",
      "[valid] 0/439 samples processed...\n",
      "valid Loss: 0.2271 Acc: 0.9180\n",
      ">> Saved checkpoint at epoch 45\n",
      "\n",
      "Epoch 46/60\n",
      "--------------------\n",
      "[train] 0/1684 samples processed...\n",
      "[train] 1280/1684 samples processed...\n",
      "train Loss: 0.2182 Acc: 0.9091\n",
      "[valid] 0/439 samples processed...\n",
      "valid Loss: 0.2149 Acc: 0.9180\n",
      "\n",
      "Epoch 47/60\n",
      "--------------------\n",
      "[train] 0/1684 samples processed...\n",
      "[train] 1280/1684 samples processed...\n",
      "train Loss: 0.2936 Acc: 0.8735\n",
      "[valid] 0/439 samples processed...\n",
      "valid Loss: 0.3104 Acc: 0.8884\n",
      "\n",
      "Epoch 48/60\n",
      "--------------------\n",
      "[train] 0/1684 samples processed...\n",
      "[train] 1280/1684 samples processed...\n",
      "train Loss: 0.2917 Acc: 0.8777\n",
      "[valid] 0/439 samples processed...\n",
      "valid Loss: 0.2491 Acc: 0.9248\n",
      "\n",
      "Epoch 49/60\n",
      "--------------------\n",
      "[train] 0/1684 samples processed...\n",
      "[train] 1280/1684 samples processed...\n",
      "train Loss: 0.2429 Acc: 0.8985\n",
      "[valid] 0/439 samples processed...\n",
      "valid Loss: 0.3188 Acc: 0.9066\n",
      "\n",
      "Epoch 50/60\n",
      "--------------------\n",
      "[train] 0/1684 samples processed...\n",
      "[train] 1280/1684 samples processed...\n",
      "train Loss: 0.2756 Acc: 0.8818\n",
      "[valid] 0/439 samples processed...\n",
      "valid Loss: 0.2716 Acc: 0.9021\n",
      ">> Saved checkpoint at epoch 50\n",
      "\n",
      "Epoch 51/60\n",
      "--------------------\n",
      "[train] 0/1684 samples processed...\n",
      "[train] 1280/1684 samples processed...\n",
      "train Loss: 0.2411 Acc: 0.9050\n",
      "[valid] 0/439 samples processed...\n",
      "valid Loss: 0.2847 Acc: 0.8861\n",
      "\n",
      "Epoch 52/60\n",
      "--------------------\n",
      "[train] 0/1684 samples processed...\n",
      "[train] 1280/1684 samples processed...\n",
      "train Loss: 0.2589 Acc: 0.8901\n",
      "[valid] 0/439 samples processed...\n",
      "valid Loss: 0.2640 Acc: 0.9134\n",
      "\n",
      "Epoch 53/60\n",
      "--------------------\n",
      "[train] 0/1684 samples processed...\n",
      "[train] 1280/1684 samples processed...\n",
      "train Loss: 0.2888 Acc: 0.8925\n",
      "[valid] 0/439 samples processed...\n",
      "valid Loss: 0.3315 Acc: 0.8815\n",
      "\n",
      "Epoch 54/60\n",
      "--------------------\n",
      "[train] 0/1684 samples processed...\n",
      "[train] 1280/1684 samples processed...\n",
      "train Loss: 0.2604 Acc: 0.8895\n",
      "[valid] 0/439 samples processed...\n",
      "valid Loss: 0.3113 Acc: 0.9043\n",
      "\n",
      "Epoch 55/60\n",
      "--------------------\n",
      "[train] 0/1684 samples processed...\n",
      "[train] 1280/1684 samples processed...\n",
      "train Loss: 0.2812 Acc: 0.8860\n",
      "[valid] 0/439 samples processed...\n",
      "valid Loss: 0.2752 Acc: 0.9089\n",
      ">> Saved checkpoint at epoch 55\n",
      "\n",
      "Epoch 56/60\n",
      "--------------------\n",
      "[train] 0/1684 samples processed...\n",
      "[train] 1280/1684 samples processed...\n",
      "train Loss: 0.2727 Acc: 0.8955\n",
      "[valid] 0/439 samples processed...\n",
      "valid Loss: 0.2549 Acc: 0.9203\n",
      "\n",
      "Epoch 57/60\n",
      "--------------------\n",
      "[train] 0/1684 samples processed...\n",
      "[train] 1280/1684 samples processed...\n",
      "train Loss: 0.2354 Acc: 0.9115\n",
      "[valid] 0/439 samples processed...\n",
      "valid Loss: 0.3250 Acc: 0.8838\n",
      "\n",
      "Epoch 58/60\n",
      "--------------------\n",
      "[train] 0/1684 samples processed...\n",
      "[train] 1280/1684 samples processed...\n",
      "train Loss: 0.2928 Acc: 0.8777\n",
      "[valid] 0/439 samples processed...\n",
      "valid Loss: 0.2868 Acc: 0.8907\n",
      "\n",
      "Epoch 59/60\n",
      "--------------------\n",
      "[train] 0/1684 samples processed...\n",
      "[train] 1280/1684 samples processed...\n",
      "train Loss: 0.2358 Acc: 0.9008\n",
      "[valid] 0/439 samples processed...\n",
      "valid Loss: 0.3446 Acc: 0.8952\n",
      "\n",
      "Epoch 60/60\n",
      "--------------------\n",
      "[train] 0/1684 samples processed...\n",
      "[train] 1280/1684 samples processed...\n",
      "train Loss: 0.2766 Acc: 0.8812\n",
      "[valid] 0/439 samples processed...\n",
      "valid Loss: 0.3337 Acc: 0.8861\n",
      ">> Saved checkpoint at epoch 60\n",
      "\n",
      "Training complete in 9m 31s\n",
      "Best val Acc: 0.9317\n"
     ]
    }
   ],
   "source": [
    "trained_model = train_model(model, criterion, optimizer, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfeb7cf8-f7ce-4e20-9997-db468dd003bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-27T15:01:58.518456Z",
     "iopub.status.busy": "2025-09-27T15:01:58.517044Z",
     "iopub.status.idle": "2025-09-27T15:02:02.147631Z",
     "shell.execute_reply": "2025-09-27T15:02:02.146524Z",
     "shell.execute_reply.started": "2025-09-27T15:01:58.518403Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B2_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B2_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/efficientnet_b2_rwightman-bcdf34b7.pth\" to /tmp/xdg_cache/torch/hub/checkpoints/efficientnet_b2_rwightman-bcdf34b7.pth\n",
      "100%|██████████| 35.2M/35.2M [00:00<00:00, 51.9MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EfficientNetWithEmbeddings(\n",
       "  (base): EfficientNet(\n",
       "    (features): Sequential(\n",
       "      (0): Conv2dNormActivation(\n",
       "        (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): SiLU(inplace=True)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "              (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (2): Conv2dNormActivation(\n",
       "              (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
       "        )\n",
       "        (1): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
       "              (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(16, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(4, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (2): Conv2dNormActivation(\n",
       "              (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.008695652173913044, mode=row)\n",
       "        )\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.017391304347826087, mode=row)\n",
       "        )\n",
       "        (1): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.026086956521739136, mode=row)\n",
       "        )\n",
       "        (2): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.034782608695652174, mode=row)\n",
       "        )\n",
       "      )\n",
       "      (3): Sequential(\n",
       "        (0): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n",
       "              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(144, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.043478260869565216, mode=row)\n",
       "        )\n",
       "        (1): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False)\n",
       "              (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.05217391304347827, mode=row)\n",
       "        )\n",
       "        (2): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False)\n",
       "              (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.06086956521739131, mode=row)\n",
       "        )\n",
       "      )\n",
       "      (4): Sequential(\n",
       "        (0): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)\n",
       "              (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.06956521739130435, mode=row)\n",
       "        )\n",
       "        (1): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)\n",
       "              (1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(528, 22, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(22, 528, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.0782608695652174, mode=row)\n",
       "        )\n",
       "        (2): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)\n",
       "              (1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(528, 22, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(22, 528, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.08695652173913043, mode=row)\n",
       "        )\n",
       "        (3): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)\n",
       "              (1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(528, 22, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(22, 528, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.09565217391304348, mode=row)\n",
       "        )\n",
       "      )\n",
       "      (5): Sequential(\n",
       "        (0): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(528, 528, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=528, bias=False)\n",
       "              (1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(528, 22, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(22, 528, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(528, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.10434782608695654, mode=row)\n",
       "        )\n",
       "        (1): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(120, 720, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(720, 720, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=720, bias=False)\n",
       "              (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(720, 30, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(30, 720, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(720, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.11304347826086956, mode=row)\n",
       "        )\n",
       "        (2): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(120, 720, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(720, 720, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=720, bias=False)\n",
       "              (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(720, 30, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(30, 720, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(720, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.12173913043478261, mode=row)\n",
       "        )\n",
       "        (3): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(120, 720, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(720, 720, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=720, bias=False)\n",
       "              (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(720, 30, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(30, 720, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(720, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.13043478260869565, mode=row)\n",
       "        )\n",
       "      )\n",
       "      (6): Sequential(\n",
       "        (0): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(120, 720, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(720, 720, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=720, bias=False)\n",
       "              (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(720, 30, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(30, 720, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(720, 208, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.1391304347826087, mode=row)\n",
       "        )\n",
       "        (1): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(208, 1248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(1248, 1248, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1248, bias=False)\n",
       "              (1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(1248, 52, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(52, 1248, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(1248, 208, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.14782608695652175, mode=row)\n",
       "        )\n",
       "        (2): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(208, 1248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(1248, 1248, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1248, bias=False)\n",
       "              (1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(1248, 52, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(52, 1248, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(1248, 208, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.1565217391304348, mode=row)\n",
       "        )\n",
       "        (3): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(208, 1248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(1248, 1248, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1248, bias=False)\n",
       "              (1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(1248, 52, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(52, 1248, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(1248, 208, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.16521739130434784, mode=row)\n",
       "        )\n",
       "        (4): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(208, 1248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(1248, 1248, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1248, bias=False)\n",
       "              (1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(1248, 52, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(52, 1248, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(1248, 208, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.17391304347826086, mode=row)\n",
       "        )\n",
       "      )\n",
       "      (7): Sequential(\n",
       "        (0): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(208, 1248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(1248, 1248, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1248, bias=False)\n",
       "              (1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(1248, 52, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(52, 1248, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(1248, 352, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.1826086956521739, mode=row)\n",
       "        )\n",
       "        (1): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(352, 2112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(2112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(2112, 2112, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2112, bias=False)\n",
       "              (1): BatchNorm2d(2112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(2112, 88, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(88, 2112, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(2112, 352, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.19130434782608696, mode=row)\n",
       "        )\n",
       "      )\n",
       "      (8): Conv2dNormActivation(\n",
       "        (0): Conv2d(352, 1408, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(1408, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): SiLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "    (classifier): Sequential(\n",
       "      (0): Dropout(p=0.3, inplace=True)\n",
       "      (1): Linear(in_features=1408, out_features=1000, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (feature_extractor): Sequential(\n",
       "    (0): Conv2dNormActivation(\n",
       "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): SiLU(inplace=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (2): Conv2dNormActivation(\n",
       "            (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
       "            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(16, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(4, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (2): Conv2dNormActivation(\n",
       "            (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.008695652173913044, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.017391304347826087, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.026086956521739136, mode=row)\n",
       "      )\n",
       "      (2): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.034782608695652174, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(144, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.043478260869565216, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False)\n",
       "            (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.05217391304347827, mode=row)\n",
       "      )\n",
       "      (2): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False)\n",
       "            (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.06086956521739131, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)\n",
       "            (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.06956521739130435, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)\n",
       "            (1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(528, 22, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(22, 528, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.0782608695652174, mode=row)\n",
       "      )\n",
       "      (2): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)\n",
       "            (1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(528, 22, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(22, 528, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.08695652173913043, mode=row)\n",
       "      )\n",
       "      (3): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)\n",
       "            (1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(528, 22, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(22, 528, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.09565217391304348, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(528, 528, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=528, bias=False)\n",
       "            (1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(528, 22, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(22, 528, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(528, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.10434782608695654, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(120, 720, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(720, 720, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=720, bias=False)\n",
       "            (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(720, 30, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(30, 720, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(720, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.11304347826086956, mode=row)\n",
       "      )\n",
       "      (2): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(120, 720, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(720, 720, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=720, bias=False)\n",
       "            (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(720, 30, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(30, 720, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(720, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.12173913043478261, mode=row)\n",
       "      )\n",
       "      (3): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(120, 720, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(720, 720, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=720, bias=False)\n",
       "            (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(720, 30, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(30, 720, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(720, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.13043478260869565, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(120, 720, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(720, 720, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=720, bias=False)\n",
       "            (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(720, 30, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(30, 720, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(720, 208, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1391304347826087, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(208, 1248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1248, 1248, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1248, bias=False)\n",
       "            (1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1248, 52, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(52, 1248, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1248, 208, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.14782608695652175, mode=row)\n",
       "      )\n",
       "      (2): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(208, 1248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1248, 1248, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1248, bias=False)\n",
       "            (1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1248, 52, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(52, 1248, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1248, 208, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1565217391304348, mode=row)\n",
       "      )\n",
       "      (3): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(208, 1248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1248, 1248, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1248, bias=False)\n",
       "            (1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1248, 52, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(52, 1248, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1248, 208, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.16521739130434784, mode=row)\n",
       "      )\n",
       "      (4): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(208, 1248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1248, 1248, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1248, bias=False)\n",
       "            (1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1248, 52, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(52, 1248, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1248, 208, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.17391304347826086, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(208, 1248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1248, 1248, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1248, bias=False)\n",
       "            (1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1248, 52, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(52, 1248, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1248, 352, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1826086956521739, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(352, 2112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(2112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(2112, 2112, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2112, bias=False)\n",
       "            (1): BatchNorm2d(2112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(2112, 88, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(88, 2112, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(2112, 352, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.19130434782608696, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (8): Conv2dNormActivation(\n",
       "      (0): Conv2d(352, 1408, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(1408, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): SiLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (pool): AdaptiveAvgPool2d(output_size=1)\n",
       "  (embedding_layer): Flatten(start_dim=1, end_dim=-1)\n",
       "  (fc): Linear(in_features=1408, out_features=11, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_model = torch.load(os.path.join(save_path, 'best_model.pth'), map_location=torch.device('cpu'))\n",
    "\n",
    "\n",
    "trained_model = EfficientNetWithEmbeddings(3)\n",
    "trained_model.load_state_dict(state_model)\n",
    "trained_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3e4d31f-7cef-4a27-b524-45f68ac09ae2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-27T15:35:22.880352Z",
     "iopub.status.busy": "2025-09-27T15:35:22.879126Z",
     "iopub.status.idle": "2025-09-27T15:35:22.902631Z",
     "shell.execute_reply": "2025-09-27T15:35:22.901494Z",
     "shell.execute_reply.started": "2025-09-27T15:35:22.880317Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "trained_model.to(device)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "214ef3ee-f4be-46fd-b193-82e83b8de39c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-30T02:12:07.477157Z",
     "iopub.status.busy": "2025-09-30T02:12:07.475686Z",
     "iopub.status.idle": "2025-09-30T02:16:55.093428Z",
     "shell.execute_reply": "2025-09-30T02:16:55.091819Z",
     "shell.execute_reply.started": "2025-09-30T02:12:07.477102Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/30\n",
      "--------------------\n",
      "[train] 0/1684 samples processed...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:139: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train] 1280/1684 samples processed...\n",
      "train Loss: 0.2298 Acc: 0.8979\n",
      "[valid] 0/439 samples processed...\n",
      "valid Loss: 0.2781 Acc: 0.9180\n",
      ">> Saved best model.\n",
      "\n",
      "Epoch 2/30\n",
      "--------------------\n",
      "[train] 0/1684 samples processed...\n",
      "[train] 1280/1684 samples processed...\n",
      "train Loss: 0.2506 Acc: 0.9074\n",
      "[valid] 0/439 samples processed...\n",
      "valid Loss: 0.2991 Acc: 0.8929\n",
      "\n",
      "Epoch 3/30\n",
      "--------------------\n",
      "[train] 0/1684 samples processed...\n",
      "[train] 1280/1684 samples processed...\n",
      "train Loss: 0.2227 Acc: 0.9157\n",
      "[valid] 0/439 samples processed...\n",
      "valid Loss: 0.3323 Acc: 0.8793\n",
      "\n",
      "Epoch 4/30\n",
      "--------------------\n",
      "[train] 0/1684 samples processed...\n",
      "[train] 1280/1684 samples processed...\n",
      "train Loss: 0.2339 Acc: 0.8949\n",
      "[valid] 0/439 samples processed...\n",
      "valid Loss: 0.2319 Acc: 0.9226\n",
      ">> Saved best model.\n",
      "\n",
      "Epoch 5/30\n",
      "--------------------\n",
      "[train] 0/1684 samples processed...\n",
      "[train] 1280/1684 samples processed...\n",
      "train Loss: 0.2775 Acc: 0.8895\n",
      "[valid] 0/439 samples processed...\n",
      "valid Loss: 0.2673 Acc: 0.9112\n",
      ">> Saved checkpoint at epoch 5\n",
      "\n",
      "Epoch 6/30\n",
      "--------------------\n",
      "[train] 0/1684 samples processed...\n",
      "[train] 1280/1684 samples processed...\n",
      "train Loss: 0.2298 Acc: 0.9014\n",
      "[valid] 0/439 samples processed...\n",
      "valid Loss: 0.2535 Acc: 0.9021\n",
      "\n",
      "Epoch 7/30\n",
      "--------------------\n",
      "[train] 0/1684 samples processed...\n",
      "[train] 1280/1684 samples processed...\n",
      "train Loss: 0.2486 Acc: 0.8895\n",
      "[valid] 0/439 samples processed...\n",
      "valid Loss: 0.1978 Acc: 0.9248\n",
      ">> Saved best model.\n",
      "\n",
      "Epoch 8/30\n",
      "--------------------\n",
      "[train] 0/1684 samples processed...\n",
      "[train] 1280/1684 samples processed...\n",
      "train Loss: 0.2426 Acc: 0.9002\n",
      "[valid] 0/439 samples processed...\n",
      "valid Loss: 0.2244 Acc: 0.9089\n",
      "\n",
      "Epoch 9/30\n",
      "--------------------\n",
      "[train] 0/1684 samples processed...\n",
      "[train] 1280/1684 samples processed...\n",
      "train Loss: 0.2063 Acc: 0.9157\n",
      "[valid] 0/439 samples processed...\n",
      "valid Loss: 0.2432 Acc: 0.9134\n",
      "\n",
      "Epoch 10/30\n",
      "--------------------\n",
      "[train] 0/1684 samples processed...\n",
      "[train] 1280/1684 samples processed...\n",
      "train Loss: 0.2273 Acc: 0.9008\n",
      "[valid] 0/439 samples processed...\n",
      "valid Loss: 0.2899 Acc: 0.8998\n",
      ">> Saved checkpoint at epoch 10\n",
      "\n",
      "Epoch 11/30\n",
      "--------------------\n",
      "[train] 0/1684 samples processed...\n",
      "[train] 1280/1684 samples processed...\n",
      "train Loss: 0.2200 Acc: 0.9086\n",
      "[valid] 0/439 samples processed...\n",
      "valid Loss: 0.3101 Acc: 0.8838\n",
      "\n",
      "Epoch 12/30\n",
      "--------------------\n",
      "[train] 0/1684 samples processed...\n",
      "[train] 1280/1684 samples processed...\n",
      "train Loss: 0.2109 Acc: 0.9204\n",
      "[valid] 0/439 samples processed...\n",
      "valid Loss: 0.2283 Acc: 0.9112\n",
      "\n",
      "Epoch 13/30\n",
      "--------------------\n",
      "[train] 0/1684 samples processed...\n",
      "[train] 1280/1684 samples processed...\n",
      "train Loss: 0.2007 Acc: 0.9157\n",
      "[valid] 0/439 samples processed...\n",
      "valid Loss: 0.2008 Acc: 0.9180\n",
      "\n",
      "Epoch 14/30\n",
      "--------------------\n",
      "[train] 0/1684 samples processed...\n",
      "[train] 1280/1684 samples processed...\n",
      "train Loss: 0.2134 Acc: 0.9157\n",
      "[valid] 0/439 samples processed...\n",
      "valid Loss: 0.2555 Acc: 0.9089\n",
      "\n",
      "Epoch 15/30\n",
      "--------------------\n",
      "[train] 0/1684 samples processed...\n",
      "[train] 1280/1684 samples processed...\n",
      "train Loss: 0.2256 Acc: 0.9014\n",
      "[valid] 0/439 samples processed...\n",
      "valid Loss: 0.2310 Acc: 0.9066\n",
      ">> Saved checkpoint at epoch 15\n",
      "\n",
      "Epoch 16/30\n",
      "--------------------\n",
      "[train] 0/1684 samples processed...\n",
      "[train] 1280/1684 samples processed...\n",
      "train Loss: 0.2321 Acc: 0.9020\n",
      "[valid] 0/439 samples processed...\n",
      "valid Loss: 0.2195 Acc: 0.9271\n",
      ">> Saved best model.\n",
      "\n",
      "Epoch 17/30\n",
      "--------------------\n",
      "[train] 0/1684 samples processed...\n",
      "[train] 1280/1684 samples processed...\n",
      "train Loss: 0.2002 Acc: 0.9175\n",
      "[valid] 0/439 samples processed...\n",
      "valid Loss: 0.2686 Acc: 0.8998\n",
      "\n",
      "Epoch 18/30\n",
      "--------------------\n",
      "[train] 0/1684 samples processed...\n",
      "[train] 1280/1684 samples processed...\n",
      "train Loss: 0.2251 Acc: 0.9032\n",
      "[valid] 0/439 samples processed...\n",
      "valid Loss: 0.2370 Acc: 0.9043\n",
      "\n",
      "Epoch 19/30\n",
      "--------------------\n",
      "[train] 0/1684 samples processed...\n",
      "[train] 1280/1684 samples processed...\n",
      "train Loss: 0.2348 Acc: 0.9026\n",
      "[valid] 0/439 samples processed...\n",
      "valid Loss: 0.2629 Acc: 0.9134\n",
      "\n",
      "Epoch 20/30\n",
      "--------------------\n",
      "[train] 0/1684 samples processed...\n",
      "[train] 1280/1684 samples processed...\n",
      "train Loss: 0.2171 Acc: 0.9151\n",
      "[valid] 0/439 samples processed...\n",
      "valid Loss: 0.2638 Acc: 0.9134\n",
      ">> Saved checkpoint at epoch 20\n",
      "\n",
      "Epoch 21/30\n",
      "--------------------\n",
      "[train] 0/1684 samples processed...\n",
      "[train] 1280/1684 samples processed...\n",
      "train Loss: 0.2409 Acc: 0.8961\n",
      "[valid] 0/439 samples processed...\n",
      "valid Loss: 0.3549 Acc: 0.8656\n",
      "\n",
      "Epoch 22/30\n",
      "--------------------\n",
      "[train] 0/1684 samples processed...\n",
      "[train] 1280/1684 samples processed...\n",
      "train Loss: 0.2399 Acc: 0.9002\n",
      "[valid] 0/439 samples processed...\n",
      "valid Loss: 0.2833 Acc: 0.9089\n",
      "\n",
      "Epoch 23/30\n",
      "--------------------\n",
      "[train] 0/1684 samples processed...\n",
      "[train] 1280/1684 samples processed...\n",
      "train Loss: 0.2017 Acc: 0.9127\n",
      "[valid] 0/439 samples processed...\n",
      "valid Loss: 0.2906 Acc: 0.8884\n",
      "\n",
      "Epoch 24/30\n",
      "--------------------\n",
      "[train] 0/1684 samples processed...\n",
      "[train] 1280/1684 samples processed...\n",
      "train Loss: 0.2091 Acc: 0.9139\n",
      "[valid] 0/439 samples processed...\n",
      "valid Loss: 0.2709 Acc: 0.9066\n",
      "\n",
      "Epoch 25/30\n",
      "--------------------\n",
      "[train] 0/1684 samples processed...\n",
      "[train] 1280/1684 samples processed...\n",
      "train Loss: 0.1884 Acc: 0.9216\n",
      "[valid] 0/439 samples processed...\n",
      "valid Loss: 0.2636 Acc: 0.8952\n",
      ">> Saved checkpoint at epoch 25\n",
      "\n",
      "Epoch 26/30\n",
      "--------------------\n",
      "[train] 0/1684 samples processed...\n",
      "[train] 1280/1684 samples processed...\n",
      "train Loss: 0.2332 Acc: 0.9044\n",
      "[valid] 0/439 samples processed...\n",
      "valid Loss: 0.2515 Acc: 0.9089\n",
      "\n",
      "Epoch 27/30\n",
      "--------------------\n",
      "[train] 0/1684 samples processed...\n",
      "[train] 1280/1684 samples processed...\n",
      "train Loss: 0.2052 Acc: 0.9169\n",
      "[valid] 0/439 samples processed...\n",
      "valid Loss: 0.2494 Acc: 0.8952\n",
      "\n",
      "Epoch 28/30\n",
      "--------------------\n",
      "[train] 0/1684 samples processed...\n",
      "[train] 1280/1684 samples processed...\n",
      "train Loss: 0.2044 Acc: 0.9175\n",
      "[valid] 0/439 samples processed...\n",
      "valid Loss: 0.2913 Acc: 0.8998\n",
      "\n",
      "Epoch 29/30\n",
      "--------------------\n",
      "[train] 0/1684 samples processed...\n",
      "[train] 1280/1684 samples processed...\n",
      "train Loss: 0.2111 Acc: 0.9086\n",
      "[valid] 0/439 samples processed...\n",
      "valid Loss: 0.2756 Acc: 0.8884\n",
      "\n",
      "Epoch 30/30\n",
      "--------------------\n",
      "[train] 0/1684 samples processed...\n",
      "[train] 1280/1684 samples processed...\n",
      "train Loss: 0.1962 Acc: 0.9216\n",
      "[valid] 0/439 samples processed...\n",
      "valid Loss: 0.2543 Acc: 0.9134\n",
      ">> Saved checkpoint at epoch 30\n",
      "\n",
      "Training complete in 4m 48s\n",
      "Best val Acc: 0.9271\n"
     ]
    }
   ],
   "source": [
    "lrb = 1e-2 * learning_rate\n",
    "num_epochs = 30\n",
    "save_path = '/home/jupyter/datasphere/filestore/training/efficientnet-b0_training-screwdriver-backbone'\n",
    "\n",
    "trained_model.to(device)\n",
    "\n",
    "for param in trained_model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "optimizer_b = optim.AdamW(model.parameters(), lr=lrb, weight_decay=1e-2)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=30)\n",
    "\n",
    "trained_back = train_model(trained_model, criterion, optimizer_b, num_epochs=num_epochs, scheduler=scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d6203f64-9f11-4bdd-a713-d8f34661b88d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-27T17:16:34.292985Z",
     "iopub.status.busy": "2025-09-27T17:16:34.291572Z",
     "iopub.status.idle": "2025-09-27T17:29:21.679951Z",
     "shell.execute_reply": "2025-09-27T17:29:21.678192Z",
     "shell.execute_reply.started": "2025-09-27T17:16:34.292932Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/30\n",
      "--------------------\n",
      "[train] 0/7582 samples processed...\n",
      "[train] 1280/7582 samples processed...\n",
      "[train] 2560/7582 samples processed...\n",
      "[train] 3840/7582 samples processed...\n",
      "[train] 5120/7582 samples processed...\n",
      "[train] 6400/7582 samples processed...\n",
      "train Loss: 0.1028 Acc: 0.9660\n",
      "[valid] 0/1997 samples processed...\n",
      "[valid] 1280/1997 samples processed...\n",
      "valid Loss: 0.1411 Acc: 0.9609\n",
      ">> Saved best model.\n",
      "\n",
      "Epoch 2/30\n",
      "--------------------\n",
      "[train] 0/7582 samples processed...\n",
      "[train] 1280/7582 samples processed...\n",
      "[train] 2560/7582 samples processed...\n",
      "[train] 3840/7582 samples processed...\n",
      "[train] 5120/7582 samples processed...\n",
      "[train] 6400/7582 samples processed...\n",
      "train Loss: 0.0973 Acc: 0.9657\n",
      "[valid] 0/1997 samples processed...\n",
      "[valid] 1280/1997 samples processed...\n",
      "valid Loss: 0.1162 Acc: 0.9659\n",
      ">> Saved best model.\n",
      "\n",
      "Epoch 3/30\n",
      "--------------------\n",
      "[train] 0/7582 samples processed...\n",
      "[train] 1280/7582 samples processed...\n",
      "[train] 2560/7582 samples processed...\n",
      "[train] 3840/7582 samples processed...\n",
      "[train] 5120/7582 samples processed...\n",
      "[train] 6400/7582 samples processed...\n",
      "train Loss: 0.1067 Acc: 0.9673\n",
      "[valid] 0/1997 samples processed...\n",
      "[valid] 1280/1997 samples processed...\n",
      "valid Loss: 0.1331 Acc: 0.9549\n",
      "\n",
      "Epoch 4/30\n",
      "--------------------\n",
      "[train] 0/7582 samples processed...\n",
      "[train] 1280/7582 samples processed...\n",
      "[train] 2560/7582 samples processed...\n",
      "[train] 3840/7582 samples processed...\n",
      "[train] 5120/7582 samples processed...\n",
      "[train] 6400/7582 samples processed...\n",
      "train Loss: 0.0819 Acc: 0.9732\n",
      "[valid] 0/1997 samples processed...\n",
      "[valid] 1280/1997 samples processed...\n",
      "valid Loss: 0.1437 Acc: 0.9579\n",
      "\n",
      "Epoch 5/30\n",
      "--------------------\n",
      "[train] 0/7582 samples processed...\n",
      "[train] 1280/7582 samples processed...\n",
      "[train] 2560/7582 samples processed...\n",
      "[train] 3840/7582 samples processed...\n",
      "[train] 5120/7582 samples processed...\n",
      "[train] 6400/7582 samples processed...\n",
      "train Loss: 0.1041 Acc: 0.9645\n",
      "[valid] 0/1997 samples processed...\n",
      "[valid] 1280/1997 samples processed...\n",
      "valid Loss: 0.1769 Acc: 0.9514\n",
      ">> Saved checkpoint at epoch 5\n",
      "\n",
      "Epoch 6/30\n",
      "--------------------\n",
      "[train] 0/7582 samples processed...\n",
      "[train] 1280/7582 samples processed...\n",
      "[train] 2560/7582 samples processed...\n",
      "[train] 3840/7582 samples processed...\n",
      "[train] 5120/7582 samples processed...\n",
      "[train] 6400/7582 samples processed...\n",
      "train Loss: 0.1117 Acc: 0.9625\n",
      "[valid] 0/1997 samples processed...\n",
      "[valid] 1280/1997 samples processed...\n",
      "valid Loss: 0.1364 Acc: 0.9609\n",
      "\n",
      "Epoch 7/30\n",
      "--------------------\n",
      "[train] 0/7582 samples processed...\n",
      "[train] 1280/7582 samples processed...\n",
      "[train] 2560/7582 samples processed...\n",
      "[train] 3840/7582 samples processed...\n",
      "[train] 5120/7582 samples processed...\n",
      "[train] 6400/7582 samples processed...\n",
      "train Loss: 0.1017 Acc: 0.9660\n",
      "[valid] 0/1997 samples processed...\n",
      "[valid] 1280/1997 samples processed...\n",
      "valid Loss: 0.1453 Acc: 0.9564\n",
      "\n",
      "Epoch 8/30\n",
      "--------------------\n",
      "[train] 0/7582 samples processed...\n",
      "[train] 1280/7582 samples processed...\n",
      "[train] 2560/7582 samples processed...\n",
      "[train] 3840/7582 samples processed...\n",
      "[train] 5120/7582 samples processed...\n",
      "[train] 6400/7582 samples processed...\n",
      "train Loss: 0.1000 Acc: 0.9665\n",
      "[valid] 0/1997 samples processed...\n",
      "[valid] 1280/1997 samples processed...\n",
      "valid Loss: 0.1030 Acc: 0.9649\n",
      "\n",
      "Epoch 9/30\n",
      "--------------------\n",
      "[train] 0/7582 samples processed...\n",
      "[train] 1280/7582 samples processed...\n",
      "[train] 2560/7582 samples processed...\n",
      "[train] 3840/7582 samples processed...\n",
      "[train] 5120/7582 samples processed...\n",
      "[train] 6400/7582 samples processed...\n",
      "train Loss: 0.0957 Acc: 0.9703\n",
      "[valid] 0/1997 samples processed...\n",
      "[valid] 1280/1997 samples processed...\n",
      "valid Loss: 0.1344 Acc: 0.9649\n",
      "\n",
      "Epoch 10/30\n",
      "--------------------\n",
      "[train] 0/7582 samples processed...\n",
      "[train] 1280/7582 samples processed...\n",
      "[train] 2560/7582 samples processed...\n",
      "[train] 3840/7582 samples processed...\n",
      "[train] 5120/7582 samples processed...\n",
      "[train] 6400/7582 samples processed...\n",
      "train Loss: 0.1043 Acc: 0.9674\n",
      "[valid] 0/1997 samples processed...\n",
      "[valid] 1280/1997 samples processed...\n",
      "valid Loss: 0.1697 Acc: 0.9494\n",
      ">> Saved checkpoint at epoch 10\n",
      "\n",
      "Epoch 11/30\n",
      "--------------------\n",
      "[train] 0/7582 samples processed...\n",
      "[train] 1280/7582 samples processed...\n",
      "[train] 2560/7582 samples processed...\n",
      "[train] 3840/7582 samples processed...\n",
      "[train] 5120/7582 samples processed...\n",
      "[train] 6400/7582 samples processed...\n",
      "train Loss: 0.1067 Acc: 0.9678\n",
      "[valid] 0/1997 samples processed...\n",
      "[valid] 1280/1997 samples processed...\n",
      "valid Loss: 0.1391 Acc: 0.9609\n",
      "\n",
      "Epoch 12/30\n",
      "--------------------\n",
      "[train] 0/7582 samples processed...\n",
      "[train] 1280/7582 samples processed...\n",
      "[train] 2560/7582 samples processed...\n",
      "[train] 3840/7582 samples processed...\n",
      "[train] 5120/7582 samples processed...\n",
      "[train] 6400/7582 samples processed...\n",
      "train Loss: 0.0796 Acc: 0.9743\n",
      "[valid] 0/1997 samples processed...\n",
      "[valid] 1280/1997 samples processed...\n",
      "valid Loss: 0.1341 Acc: 0.9675\n",
      ">> Saved best model.\n",
      "\n",
      "Epoch 13/30\n",
      "--------------------\n",
      "[train] 0/7582 samples processed...\n",
      "[train] 1280/7582 samples processed...\n",
      "[train] 2560/7582 samples processed...\n",
      "[train] 3840/7582 samples processed...\n",
      "[train] 5120/7582 samples processed...\n",
      "[train] 6400/7582 samples processed...\n",
      "train Loss: 0.1020 Acc: 0.9681\n",
      "[valid] 0/1997 samples processed...\n",
      "[valid] 1280/1997 samples processed...\n",
      "valid Loss: 0.1141 Acc: 0.9695\n",
      ">> Saved best model.\n",
      "\n",
      "Epoch 14/30\n",
      "--------------------\n",
      "[train] 0/7582 samples processed...\n",
      "[train] 1280/7582 samples processed...\n",
      "[train] 2560/7582 samples processed...\n",
      "[train] 3840/7582 samples processed...\n",
      "[train] 5120/7582 samples processed...\n",
      "[train] 6400/7582 samples processed...\n",
      "train Loss: 0.0959 Acc: 0.9666\n",
      "[valid] 0/1997 samples processed...\n",
      "[valid] 1280/1997 samples processed...\n",
      "valid Loss: 0.0995 Acc: 0.9705\n",
      ">> Saved best model.\n",
      "\n",
      "Epoch 15/30\n",
      "--------------------\n",
      "[train] 0/7582 samples processed...\n",
      "[train] 1280/7582 samples processed...\n",
      "[train] 2560/7582 samples processed...\n",
      "[train] 3840/7582 samples processed...\n",
      "[train] 5120/7582 samples processed...\n",
      "[train] 6400/7582 samples processed...\n",
      "train Loss: 0.0857 Acc: 0.9715\n",
      "[valid] 0/1997 samples processed...\n",
      "[valid] 1280/1997 samples processed...\n",
      "valid Loss: 0.1147 Acc: 0.9680\n",
      ">> Saved checkpoint at epoch 15\n",
      "\n",
      "Epoch 16/30\n",
      "--------------------\n",
      "[train] 0/7582 samples processed...\n",
      "[train] 1280/7582 samples processed...\n",
      "[train] 2560/7582 samples processed...\n",
      "[train] 3840/7582 samples processed...\n",
      "[train] 5120/7582 samples processed...\n",
      "[train] 6400/7582 samples processed...\n",
      "train Loss: 0.0980 Acc: 0.9682\n",
      "[valid] 0/1997 samples processed...\n",
      "[valid] 1280/1997 samples processed...\n",
      "valid Loss: 0.1458 Acc: 0.9624\n",
      "\n",
      "Epoch 17/30\n",
      "--------------------\n",
      "[train] 0/7582 samples processed...\n",
      "[train] 1280/7582 samples processed...\n",
      "[train] 2560/7582 samples processed...\n",
      "[train] 3840/7582 samples processed...\n",
      "[train] 5120/7582 samples processed...\n",
      "[train] 6400/7582 samples processed...\n",
      "train Loss: 0.0839 Acc: 0.9712\n",
      "[valid] 0/1997 samples processed...\n",
      "[valid] 1280/1997 samples processed...\n",
      "valid Loss: 0.1521 Acc: 0.9599\n",
      "\n",
      "Epoch 18/30\n",
      "--------------------\n",
      "[train] 0/7582 samples processed...\n",
      "[train] 1280/7582 samples processed...\n",
      "[train] 2560/7582 samples processed...\n",
      "[train] 3840/7582 samples processed...\n",
      "[train] 5120/7582 samples processed...\n",
      "[train] 6400/7582 samples processed...\n",
      "train Loss: 0.1019 Acc: 0.9669\n",
      "[valid] 0/1997 samples processed...\n",
      "[valid] 1280/1997 samples processed...\n",
      "valid Loss: 0.1249 Acc: 0.9690\n",
      "\n",
      "Epoch 19/30\n",
      "--------------------\n",
      "[train] 0/7582 samples processed...\n",
      "[train] 1280/7582 samples processed...\n",
      "[train] 2560/7582 samples processed...\n",
      "[train] 3840/7582 samples processed...\n",
      "[train] 5120/7582 samples processed...\n",
      "[train] 6400/7582 samples processed...\n",
      "train Loss: 0.0819 Acc: 0.9724\n",
      "[valid] 0/1997 samples processed...\n",
      "[valid] 1280/1997 samples processed...\n",
      "valid Loss: 0.1745 Acc: 0.9584\n",
      "\n",
      "Epoch 20/30\n",
      "--------------------\n",
      "[train] 0/7582 samples processed...\n",
      "[train] 1280/7582 samples processed...\n",
      "[train] 2560/7582 samples processed...\n",
      "[train] 3840/7582 samples processed...\n",
      "[train] 5120/7582 samples processed...\n",
      "[train] 6400/7582 samples processed...\n",
      "train Loss: 0.0870 Acc: 0.9710\n",
      "[valid] 0/1997 samples processed...\n",
      "[valid] 1280/1997 samples processed...\n",
      "valid Loss: 0.1285 Acc: 0.9649\n",
      ">> Saved checkpoint at epoch 20\n",
      "\n",
      "Epoch 21/30\n",
      "--------------------\n",
      "[train] 0/7582 samples processed...\n",
      "[train] 1280/7582 samples processed...\n",
      "[train] 2560/7582 samples processed...\n",
      "[train] 3840/7582 samples processed...\n",
      "[train] 5120/7582 samples processed...\n",
      "[train] 6400/7582 samples processed...\n",
      "train Loss: 0.0960 Acc: 0.9702\n",
      "[valid] 0/1997 samples processed...\n",
      "[valid] 1280/1997 samples processed...\n",
      "valid Loss: 0.1551 Acc: 0.9559\n",
      "\n",
      "Epoch 22/30\n",
      "--------------------\n",
      "[train] 0/7582 samples processed...\n",
      "[train] 1280/7582 samples processed...\n",
      "[train] 2560/7582 samples processed...\n",
      "[train] 3840/7582 samples processed...\n",
      "[train] 5120/7582 samples processed...\n",
      "[train] 6400/7582 samples processed...\n",
      "train Loss: 0.0970 Acc: 0.9657\n",
      "[valid] 0/1997 samples processed...\n",
      "[valid] 1280/1997 samples processed...\n",
      "valid Loss: 0.1487 Acc: 0.9614\n",
      "\n",
      "Epoch 23/30\n",
      "--------------------\n",
      "[train] 0/7582 samples processed...\n",
      "[train] 1280/7582 samples processed...\n",
      "[train] 2560/7582 samples processed...\n",
      "[train] 3840/7582 samples processed...\n",
      "[train] 5120/7582 samples processed...\n",
      "[train] 6400/7582 samples processed...\n",
      "train Loss: 0.0942 Acc: 0.9681\n",
      "[valid] 0/1997 samples processed...\n",
      "[valid] 1280/1997 samples processed...\n",
      "valid Loss: 0.1161 Acc: 0.9664\n",
      "\n",
      "Epoch 24/30\n",
      "--------------------\n",
      "[train] 0/7582 samples processed...\n",
      "[train] 1280/7582 samples processed...\n",
      "[train] 2560/7582 samples processed...\n",
      "[train] 3840/7582 samples processed...\n",
      "[train] 5120/7582 samples processed...\n",
      "[train] 6400/7582 samples processed...\n",
      "train Loss: 0.0828 Acc: 0.9740\n",
      "[valid] 0/1997 samples processed...\n",
      "[valid] 1280/1997 samples processed...\n",
      "valid Loss: 0.1028 Acc: 0.9675\n",
      "\n",
      "Epoch 25/30\n",
      "--------------------\n",
      "[train] 0/7582 samples processed...\n",
      "[train] 1280/7582 samples processed...\n",
      "[train] 2560/7582 samples processed...\n",
      "[train] 3840/7582 samples processed...\n",
      "[train] 5120/7582 samples processed...\n",
      "[train] 6400/7582 samples processed...\n",
      "train Loss: 0.0854 Acc: 0.9712\n",
      "[valid] 0/1997 samples processed...\n",
      "[valid] 1280/1997 samples processed...\n",
      "valid Loss: 0.1251 Acc: 0.9675\n",
      ">> Saved checkpoint at epoch 25\n",
      "\n",
      "Epoch 26/30\n",
      "--------------------\n",
      "[train] 0/7582 samples processed...\n",
      "[train] 1280/7582 samples processed...\n",
      "[train] 2560/7582 samples processed...\n",
      "[train] 3840/7582 samples processed...\n",
      "[train] 5120/7582 samples processed...\n",
      "[train] 6400/7582 samples processed...\n",
      "train Loss: 0.0860 Acc: 0.9718\n",
      "[valid] 0/1997 samples processed...\n",
      "[valid] 1280/1997 samples processed...\n",
      "valid Loss: 0.1270 Acc: 0.9629\n",
      "\n",
      "Epoch 27/30\n",
      "--------------------\n",
      "[train] 0/7582 samples processed...\n",
      "[train] 1280/7582 samples processed...\n",
      "[train] 2560/7582 samples processed...\n",
      "[train] 3840/7582 samples processed...\n",
      "[train] 5120/7582 samples processed...\n",
      "[train] 6400/7582 samples processed...\n",
      "train Loss: 0.0940 Acc: 0.9691\n",
      "[valid] 0/1997 samples processed...\n",
      "[valid] 1280/1997 samples processed...\n",
      "valid Loss: 0.1819 Acc: 0.9549\n",
      "\n",
      "Epoch 28/30\n",
      "--------------------\n",
      "[train] 0/7582 samples processed...\n",
      "[train] 1280/7582 samples processed...\n",
      "[train] 2560/7582 samples processed...\n",
      "[train] 3840/7582 samples processed...\n",
      "[train] 5120/7582 samples processed...\n",
      "[train] 6400/7582 samples processed...\n",
      "train Loss: 0.0848 Acc: 0.9711\n",
      "[valid] 0/1997 samples processed...\n",
      "[valid] 1280/1997 samples processed...\n",
      "valid Loss: 0.1774 Acc: 0.9559\n",
      "\n",
      "Epoch 29/30\n",
      "--------------------\n",
      "[train] 0/7582 samples processed...\n",
      "[train] 1280/7582 samples processed...\n",
      "[train] 2560/7582 samples processed...\n",
      "[train] 3840/7582 samples processed...\n",
      "[train] 5120/7582 samples processed...\n",
      "[train] 6400/7582 samples processed...\n",
      "train Loss: 0.0963 Acc: 0.9660\n",
      "[valid] 0/1997 samples processed...\n",
      "[valid] 1280/1997 samples processed...\n",
      "valid Loss: 0.1295 Acc: 0.9634\n",
      "\n",
      "Epoch 30/30\n",
      "--------------------\n",
      "[train] 0/7582 samples processed...\n",
      "[train] 1280/7582 samples processed...\n",
      "[train] 2560/7582 samples processed...\n",
      "[train] 3840/7582 samples processed...\n",
      "[train] 5120/7582 samples processed...\n",
      "[train] 6400/7582 samples processed...\n",
      "train Loss: 0.0858 Acc: 0.9699\n",
      "[valid] 0/1997 samples processed...\n",
      "[valid] 1280/1997 samples processed...\n",
      "valid Loss: 0.1381 Acc: 0.9629\n",
      ">> Saved checkpoint at epoch 30\n",
      "\n",
      "Training complete in 12m 47s\n",
      "Best val Acc: 0.9705\n"
     ]
    }
   ],
   "source": [
    "trained_back = train_model(trained_back, criterion, optimizer, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2391efa3-cd09-4d0a-b39e-acd796d22857",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-30T02:20:20.328602Z",
     "iopub.status.busy": "2025-09-30T02:20:20.327098Z",
     "iopub.status.idle": "2025-09-30T02:20:24.714411Z",
     "shell.execute_reply": "2025-09-30T02:20:24.712870Z",
     "shell.execute_reply.started": "2025-09-30T02:20:20.328564Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "tfs = T.Compose([\n",
    "    T.Resize((224, 224)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\n",
    "test_dataset = datasets.ImageFolder('/home/jupyter/datasphere/filestore/datasets/tmp/test', transform=tfs)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=True, num_workers=2)\n",
    "\n",
    "story_df = pd.DataFrame(columns=['cls', 'conf', 'y'])\n",
    "\n",
    "\n",
    "for i, (inputs, labels) in enumerate(test_loader):\n",
    "    with torch.no_grad():\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        logits = trained_back(inputs)\n",
    "        probs = torch.softmax(logits, dim=1).cpu().numpy()[0]\n",
    "        cls = int(np.argmax(probs))\n",
    "        conf = float(np.max(probs))\n",
    "        story_df.loc[i] = {'cls': cls, 'conf': conf, 'y': labels.cpu().numpy()[0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ea3d6fb8-496c-4b79-a37f-0411f53b28d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-30T02:20:31.503868Z",
     "iopub.status.busy": "2025-09-30T02:20:31.502774Z",
     "iopub.status.idle": "2025-09-30T02:20:34.725276Z",
     "shell.execute_reply": "2025-09-30T02:20:34.724145Z",
     "shell.execute_reply.started": "2025-09-30T02:20:31.503829Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f2f5f6c9c90>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cm = confusion_matrix(story_df.y, story_df.cls)\n",
    "ConfusionMatrixDisplay(cm).plot(cmap=plt.cm.Greens_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63dfb71-3d5c-40c2-baba-3a027b34ab5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataSphere Kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
